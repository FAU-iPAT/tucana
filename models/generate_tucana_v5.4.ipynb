{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2018 FAU-iPAT (http://ipat.uni-erlangen.de/)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model generation\n",
    "This notebook generates the keras model \"Tucana v5.4\" which is used to find to location of peaks in a given FFT. The model takes as inputs a 6 feature thick data for real, imaginary and absolute value of 2 different window functions. The output is a 256 binary vector whether or not a peak was detected at the according location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, Dense, Concatenate, Flatten, Dropout, MaxPooling1D, Multiply, Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the input tensor\n",
    "The input shape is $(256, 6)$, meaning the length of the input fourier transformation is $256$ and for each point $6$ features are given. Those features are the absolute, real and imaginary compontents of the transformation for each of the rectangular and the hanning window function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_count = 2\n",
    "shape_input = (256, 3*window_count)\n",
    "tensor_input = Input(shape=shape_input, name='input')\n",
    "tensor_data = tensor_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the initial feature preparation stem\n",
    "Here two blocks of parallel width-$1$ and width-$3$ convolutions are applied. Those two blocks are intended to recombine the given features into more significant features by either recombining the features at the location or combine with the neighbouring values. Each block passes through its input features and adds to new features. Thus the number of features within those blocks is increased from $6$ features at the input to $128$ features at its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of new features to get to total 64 features at the end\n",
    "feature_remain = 64 - int(tensor_data.shape[-1])\n",
    "feature_recombine = int(feature_remain / 2)\n",
    "feature_conv = feature_remain - feature_recombine\n",
    "# Create convolutions layers and concatenate them with input features\n",
    "tensor_recombine = Conv1D(feature_recombine, 1, activation='relu', padding='same', name='recombine1')(tensor_data)\n",
    "tensor_conv = Conv1D(feature_conv, 3, activation='relu', padding='same', name='conv1')(tensor_data)\n",
    "tensor_data = Concatenate(name='data2')([tensor_data, tensor_recombine, tensor_conv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create convolutions layers and concatenate them with input features\n",
    "tensor_recombine = Conv1D(32, 1, activation='relu', padding='same', name='recombine2')(tensor_data)\n",
    "tensor_conv = Conv1D(32, 3, activation='relu', padding='same', name='conv2')(tensor_data)\n",
    "tensor_data = Concatenate(name='data3')([tensor_data, tensor_recombine, tensor_conv])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the inception layers\n",
    "Here three Inception blocks are attached to the previous layers. Each of the blocks is identically created by the following function. As can be seen in the function the Inception blocks contain 4 parallel branches (Maxpooling, width-$1$ convolution, width-$3$ convolution and width-$5$ convolution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add an Inception like block to the input tensor\n",
    "def make_inception(prefix, tensor_input):\n",
    "    # MaxPooling branch\n",
    "    tensor_pool = MaxPooling1D(3, strides=1, padding='same', name=prefix+'pool1')(tensor_input)\n",
    "    tensor_pool = Conv1D(32, 1, activation='relu', padding='same', name=prefix+'pool2')(tensor_pool)\n",
    "    # 1x1 recombination branch\n",
    "    tensor_1x1 = Conv1D(32, 1, activation='relu', padding='same', name=prefix+'1x1')(tensor_input)\n",
    "    # 3x3 branch\n",
    "    tensor_3x3 = Conv1D(16, 1, activation='relu', padding='same', name=prefix+'3x3_1')(tensor_input)\n",
    "    tensor_3x3 = Conv1D(32, 3, activation='relu', padding='same', name=prefix+'3x3_2')(tensor_3x3)\n",
    "    # 5x5 branch\n",
    "    tensor_5x5 = Conv1D(16, 1, activation='relu', padding='same', name=prefix+'5x5_1')(tensor_input)\n",
    "    tensor_5x5 = Conv1D(32, 5, activation='relu', padding='same', name=prefix+'5x5_2')(tensor_5x5)\n",
    "    # Combine all branches\n",
    "    return Concatenate(name=prefix+'result')([tensor_pool, tensor_1x1, tensor_3x3, tensor_5x5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the three Inception blocks to the neural network\n",
    "tensor_data = make_inception('inception1_', tensor_data)\n",
    "tensor_data = make_inception('inception2_', tensor_data)\n",
    "tensor_data = make_inception('inception3_', tensor_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the final logic layers\n",
    "The final layers of the neural network are used to reduce the dimensionality of the features from the $128$ features at the input of the block to the single output feature at the end. Also dropout is applied within the block to prevent overfitting of the network to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_reduce = Conv1D(32, 1, activation='relu', padding='same', name='reduce')(tensor_data)\n",
    "tensor_data = Dropout(0.5, name='dropout1')(tensor_reduce)\n",
    "tensor_data = Conv1D(24, 3, activation='relu', padding='same', name='final1')(tensor_data)\n",
    "tensor_data = Dropout(0.5, name='dropout2')(tensor_data)\n",
    "tensor_data = Conv1D(16, 3, activation='relu', padding='same', name='final2')(tensor_data)\n",
    "tensor_data = Conv1D(1, 1, activation='sigmoid', padding='same', name='final3')(tensor_data)\n",
    "tensor_result = Reshape((256,), name='output')(tensor_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers = 38\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input (InputLayer)               (None, 256, 6)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "recombine1 (Conv1D)              (None, 256, 29)       203         input[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                   (None, 256, 29)       551         input[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "data2 (Concatenate)              (None, 256, 64)       0           input[0][0]                      \n",
      "                                                                   recombine1[0][0]                 \n",
      "                                                                   conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "recombine2 (Conv1D)              (None, 256, 32)       2080        data2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2 (Conv1D)                   (None, 256, 32)       6176        data2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "data3 (Concatenate)              (None, 256, 128)      0           data2[0][0]                      \n",
      "                                                                   recombine2[0][0]                 \n",
      "                                                                   conv2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "inception1_pool1 (MaxPooling1D)  (None, 256, 128)      0           data3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "inception1_3x3_1 (Conv1D)        (None, 256, 16)       2064        data3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "inception1_5x5_1 (Conv1D)        (None, 256, 16)       2064        data3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "inception1_pool2 (Conv1D)        (None, 256, 32)       4128        inception1_pool1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "inception1_1x1 (Conv1D)          (None, 256, 32)       4128        data3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "inception1_3x3_2 (Conv1D)        (None, 256, 32)       1568        inception1_3x3_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "inception1_5x5_2 (Conv1D)        (None, 256, 32)       2592        inception1_5x5_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "inception1_result (Concatenate)  (None, 256, 128)      0           inception1_pool2[0][0]           \n",
      "                                                                   inception1_1x1[0][0]             \n",
      "                                                                   inception1_3x3_2[0][0]           \n",
      "                                                                   inception1_5x5_2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "inception2_pool1 (MaxPooling1D)  (None, 256, 128)      0           inception1_result[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "inception2_3x3_1 (Conv1D)        (None, 256, 16)       2064        inception1_result[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "inception2_5x5_1 (Conv1D)        (None, 256, 16)       2064        inception1_result[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "inception2_pool2 (Conv1D)        (None, 256, 32)       4128        inception2_pool1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "inception2_1x1 (Conv1D)          (None, 256, 32)       4128        inception1_result[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "inception2_3x3_2 (Conv1D)        (None, 256, 32)       1568        inception2_3x3_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "inception2_5x5_2 (Conv1D)        (None, 256, 32)       2592        inception2_5x5_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "inception2_result (Concatenate)  (None, 256, 128)      0           inception2_pool2[0][0]           \n",
      "                                                                   inception2_1x1[0][0]             \n",
      "                                                                   inception2_3x3_2[0][0]           \n",
      "                                                                   inception2_5x5_2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "inception3_pool1 (MaxPooling1D)  (None, 256, 128)      0           inception2_result[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "inception3_3x3_1 (Conv1D)        (None, 256, 16)       2064        inception2_result[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "inception3_5x5_1 (Conv1D)        (None, 256, 16)       2064        inception2_result[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "inception3_pool2 (Conv1D)        (None, 256, 32)       4128        inception3_pool1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "inception3_1x1 (Conv1D)          (None, 256, 32)       4128        inception2_result[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "inception3_3x3_2 (Conv1D)        (None, 256, 32)       1568        inception3_3x3_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "inception3_5x5_2 (Conv1D)        (None, 256, 32)       2592        inception3_5x5_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "inception3_result (Concatenate)  (None, 256, 128)      0           inception3_pool2[0][0]           \n",
      "                                                                   inception3_1x1[0][0]             \n",
      "                                                                   inception3_3x3_2[0][0]           \n",
      "                                                                   inception3_5x5_2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "reduce (Conv1D)                  (None, 256, 32)       4128        inception3_result[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout1 (Dropout)               (None, 256, 32)       0           reduce[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "final1 (Conv1D)                  (None, 256, 24)       2328        dropout1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout2 (Dropout)               (None, 256, 24)       0           final1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "final2 (Conv1D)                  (None, 256, 16)       1168        dropout2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "final3 (Conv1D)                  (None, 256, 1)        17          final2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "output (Reshape)                 (None, 256)           0           final3[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 66,283\n",
      "Trainable params: 66,283\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(tensor_input, tensor_result, name='TucanaV5.4')\n",
    "print('Number of layers = {}'.format(len(model.layers)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json = model.to_json()\n",
    "with open(\"./tucana_v5.4.json\", \"w\") as file:\n",
    "    file.write(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2018 FAU-iPAT (http://ipat.uni-erlangen.de/)\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
